#!/usr/bin/env python3
"""
Sentiment Classification Methodology Documentation and Analysis
Provides detailed criteria and examples for Tesla tweet sentiment classification
"""

import json
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from collections import Counter
from typing import Dict, List, Any

def load_analysis_data():
    """Load the multi-condition analysis data"""
    try:
        df = pd.read_csv('multi_condition_analysis.csv')
        with open('raw_tweets.json', 'r', encoding='utf-8') as f:
            tweets = json.load(f)
        return df, tweets
    except Exception as e:
        print(f"Error loading data: {e}")
        return None, None

def analyze_sentiment_distribution(df: pd.DataFrame):
    """Analyze the distribution of sentiments and their characteristics"""
    
    # Sentiment distribution
    sentiment_counts = df['sentiment'].value_counts()
    
    # Confidence scores by sentiment
    confidence_by_sentiment = df.groupby('sentiment')['confidence'].agg(['mean', 'std', 'min', 'max'])
    
    # Sample tweets for each sentiment
    samples = {}
    for sentiment in ['BULLISH', 'BEARISH', 'NEUTRAL']:
        sentiment_tweets = df[df['sentiment'] == sentiment].nlargest(5, 'confidence')
        samples[sentiment] = sentiment_tweets[['tweet_text', 'confidence']].to_dict('records')
    
    return sentiment_counts, confidence_by_sentiment, samples

def extract_classification_patterns(df: pd.DataFrame):
    """Extract common patterns in sentiment classification"""
    
    patterns = {
        'BULLISH': {
            'keywords': [],
            'phrases': [],
            'topics': Counter(),
            'characteristics': []
        },
        'BEARISH': {
            'keywords': [],
            'phrases': [],
            'topics': Counter(),
            'characteristics': []
        },
        'NEUTRAL': {
            'keywords': [],
            'phrases': [],
            'topics': Counter(),
            'characteristics': []
        }
    }
    
    # Common bullish indicators
    bullish_keywords = [
        'amazing', 'great', 'incredible', 'breakthrough', 'record', 'best',
        'revolutionary', 'game-changing', 'proud', 'excited', 'love', 'ğŸš€',
        'milestone', 'achievement', 'success', 'leading', 'dominating'
    ]
    
    # Common bearish indicators
    bearish_keywords = [
        'problem', 'issue', 'difficult', 'challenge', 'delay', 'recall',
        'investigation', 'concern', 'risk', 'unfortunately', 'struggle',
        'failure', 'disappointing', 'setback'
    ]
    
    # Common neutral indicators
    neutral_keywords = [
        'update', 'information', 'fact', 'data', 'report', 'status',
        'currently', 'working on', 'in progress', 'planned', 'scheduled'
    ]
    
    # Analyze each sentiment group
    for sentiment in ['BULLISH', 'BEARISH', 'NEUTRAL']:
        sentiment_df = df[df['sentiment'] == sentiment]
        
        # Count keyword occurrences
        for _, row in sentiment_df.iterrows():
            text = row['tweet_text'].lower()
            
            # Count topics
            patterns[sentiment]['topics'][row.get('topic_category', 'OTHER')] += 1
            
            # Find keywords
            if sentiment == 'BULLISH':
                for keyword in bullish_keywords:
                    if keyword.lower() in text:
                        patterns[sentiment]['keywords'].append(keyword)
            elif sentiment == 'BEARISH':
                for keyword in bearish_keywords:
                    if keyword.lower() in text:
                        patterns[sentiment]['keywords'].append(keyword)
            else:
                for keyword in neutral_keywords:
                    if keyword.lower() in text:
                        patterns[sentiment]['keywords'].append(keyword)
    
    return patterns

def create_methodology_visualizations(df: pd.DataFrame, output_dir: str):
    """Create visualizations explaining the classification methodology"""
    
    plt.style.use('seaborn-v0_8-darkgrid')
    
    # 1. Sentiment distribution pie chart
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 7))
    
    sentiment_counts = df['sentiment'].value_counts()
    colors = {'BULLISH': 'green', 'BEARISH': 'red', 'NEUTRAL': 'gray'}
    
    ax1.pie(sentiment_counts.values, labels=sentiment_counts.index, autopct='%1.1f%%',
            colors=[colors.get(s, 'blue') for s in sentiment_counts.index])
    ax1.set_title('Distribution of Sentiment Classifications', fontsize=14)
    
    # 2. Confidence score distribution by sentiment
    sentiments = ['BULLISH', 'BEARISH', 'NEUTRAL']
    confidence_data = [df[df['sentiment'] == s]['confidence'].values for s in sentiments]
    
    bp = ax2.boxplot(confidence_data, labels=sentiments, patch_artist=True)
    for patch, sentiment in zip(bp['boxes'], sentiments):
        patch.set_facecolor(colors.get(sentiment, 'blue'))
    
    ax2.set_title('LLM Confidence Scores by Sentiment', fontsize=14)
    ax2.set_ylabel('Confidence Score', fontsize=12)
    ax2.set_ylim(0, 1.1)
    ax2.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig(f'{output_dir}/sentiment_methodology_overview.png', dpi=300, bbox_inches='tight')
    plt.close()
    
    # 3. Topic distribution by sentiment
    fig, axes = plt.subplots(1, 3, figsize=(18, 6))
    
    for idx, sentiment in enumerate(sentiments):
        ax = axes[idx]
        sentiment_df = df[df['sentiment'] == sentiment]
        topic_counts = sentiment_df['topic_category'].value_counts()
        
        if not topic_counts.empty:
            ax.bar(range(len(topic_counts)), topic_counts.values, 
                   color=colors.get(sentiment, 'blue'), alpha=0.7)
            ax.set_xticks(range(len(topic_counts)))
            ax.set_xticklabels(topic_counts.index, rotation=45, ha='right')
            ax.set_title(f'{sentiment} Topics', fontsize=14)
            ax.set_ylabel('Count', fontsize=12)
            ax.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig(f'{output_dir}/sentiment_topic_distribution.png', dpi=300, bbox_inches='tight')
    plt.close()
    
    # 4. Characteristics comparison
    fig, ax = plt.subplots(figsize=(12, 8))
    
    characteristics = ['is_product_announcement', 'contains_metrics', 'forward_looking']
    char_labels = ['Product\nAnnouncement', 'Contains\nMetrics', 'Forward\nLooking']
    
    x = np.arange(len(char_labels))
    width = 0.25
    
    for i, sentiment in enumerate(sentiments):
        sentiment_df = df[df['sentiment'] == sentiment]
        percentages = [
            (sentiment_df[char] == True).sum() / len(sentiment_df) * 100
            for char in characteristics
        ]
        
        ax.bar(x + i*width, percentages, width, label=sentiment, 
               color=colors.get(sentiment, 'blue'), alpha=0.8)
    
    ax.set_xlabel('Tweet Characteristics', fontsize=14)
    ax.set_ylabel('Percentage of Tweets (%)', fontsize=14)
    ax.set_title('Tweet Characteristics by Sentiment', fontsize=16)
    ax.set_xticks(x + width)
    ax.set_xticklabels(char_labels)
    ax.legend()
    ax.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig(f'{output_dir}/sentiment_characteristics.png', dpi=300, bbox_inches='tight')
    plt.close()

def generate_methodology_report(df: pd.DataFrame, patterns: Dict, samples: Dict, output_dir: str):
    """Generate detailed methodology report"""
    
    report_path = f'{output_dir}/sentiment_classification_methodology_report.md'
    
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write("# Tesla Tweet Sentiment Classification Methodology\n\n")
        f.write("## å®Œå…¨ãªå†ç¾å¯èƒ½æ€§ã®ãŸã‚ã®è©³ç´°æ–‡æ›¸\n\n")
        f.write(f"**ä½œæˆæ—¥æ™‚**: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
        
        # 1. Classification Process
        f.write("## 1. åˆ†é¡ãƒ—ãƒ­ã‚»ã‚¹\n\n")
        f.write("### ä½¿ç”¨ã—ãŸLLMã¨è¨­å®š\n")
        f.write("- **Primary LLM**: OpenAI GPT-3.5-turbo\n")
        f.write("- **Fallback LLM**: Anthropic Claude-3-haiku\n")
        f.write("- **Temperature**: 0.1 (ä¸€è²«æ€§ã®ãŸã‚ä½æ¸©è¨­å®š)\n")
        f.write("- **Max Tokens**: 150\n\n")
        
        f.write("### LLMãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆå®Œå…¨ç‰ˆï¼‰\n")
        f.write("```\n")
        f.write("Analyze the following tweet from Elon Musk about Tesla and classify it as:\n")
        f.write("1. BULLISH (positive about Tesla's future, products, or performance)\n")
        f.write("2. BEARISH (negative or cautious about Tesla)\n")
        f.write("3. NEUTRAL (factual, mixed, or unclear sentiment)\n")
        f.write("\n")
        f.write("Also provide a confidence score (0-1) and a brief reason.\n")
        f.write("\n")
        f.write('Tweet: "{tweet_text}"\n')
        f.write("\n")
        f.write("Respond in JSON format:\n")
        f.write('{"sentiment": "BULLISH/BEARISH/NEUTRAL", "confidence": 0.0-1.0, "reason": "brief explanation"}\n')
        f.write("```\n\n")
        
        # 2. Classification Criteria
        f.write("## 2. è©³ç´°ãªåˆ†é¡åŸºæº–\n\n")
        
        f.write("### BULLISHï¼ˆå¼·æ°—ï¼‰ã®åˆ¤æ–­åŸºæº–\n")
        f.write("ä»¥ä¸‹ã®è¦ç´ ã‚’å«ã‚€ãƒ„ã‚¤ãƒ¼ãƒˆã¯å¼·æ°—ã¨åˆ†é¡ã•ã‚Œã‚‹å‚¾å‘:\n\n")
        f.write("**ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ»ãƒ•ãƒ¬ãƒ¼ã‚º**:\n")
        f.write("- ãƒã‚¸ãƒ†ã‚£ãƒ–ãªå½¢å®¹è©: amazing, great, incredible, breakthrough, revolutionary\n")
        f.write("- æˆæœã‚’ç¤ºã™è¨€è‘‰: record, milestone, achievement, success, leading\n")
        f.write("- å°†æ¥ã¸ã®æœŸå¾…: excited, proud, game-changing\n")
        f.write("- çµµæ–‡å­—: ğŸš€, â¤ï¸, ğŸ”¥\n\n")
        
        f.write("**æ–‡è„ˆçš„è¦ç´ **:\n")
        f.write("- æ–°è£½å“ã‚„æ©Ÿèƒ½ã®æˆåŠŸã‚’å ±å‘Š\n")
        f.write("- ç”Ÿç”£è¨˜éŒ²ã‚„è²©å£²è¨˜éŒ²ã®é”æˆ\n")
        f.write("- æŠ€è¡“çš„ãƒ–ãƒ¬ãƒ¼ã‚¯ã‚¹ãƒ«ãƒ¼ã®ç™ºè¡¨\n")
        f.write("- ãƒãƒ¼ãƒ ã‚„è£½å“ã¸ã®è³è³›\n\n")
        
        f.write("### BEARISHï¼ˆå¼±æ°—ï¼‰ã®åˆ¤æ–­åŸºæº–\n")
        f.write("ä»¥ä¸‹ã®è¦ç´ ã‚’å«ã‚€ãƒ„ã‚¤ãƒ¼ãƒˆã¯å¼±æ°—ã¨åˆ†é¡ã•ã‚Œã‚‹å‚¾å‘:\n\n")
        f.write("**ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ»ãƒ•ãƒ¬ãƒ¼ã‚º**:\n")
        f.write("- å•é¡Œã‚’ç¤ºã™è¨€è‘‰: problem, issue, difficult, challenge, delay\n")
        f.write("- ãƒã‚¬ãƒ†ã‚£ãƒ–ãªçµæœ: recall, investigation, concern, risk\n")
        f.write("- å¤±æ•—ã‚„æŒ«æŠ˜: failure, disappointing, setback, unfortunately\n\n")
        
        f.write("**æ–‡è„ˆçš„è¦ç´ **:\n")
        f.write("- ç”Ÿç”£ã‚„é…é€ã®é…å»¶\n")
        f.write("- æŠ€è¡“çš„ãªå•é¡Œã‚„æ¬ é™¥\n")
        f.write("- è¦åˆ¶ä¸Šã®æ‡¸å¿µã‚„èª¿æŸ»\n")
        f.write("- ç›®æ¨™æœªé”æˆã®å ±å‘Š\n\n")
        
        f.write("### NEUTRALï¼ˆä¸­ç«‹ï¼‰ã®åˆ¤æ–­åŸºæº–\n")
        f.write("ä»¥ä¸‹ã®è¦ç´ ã‚’å«ã‚€ãƒ„ã‚¤ãƒ¼ãƒˆã¯ä¸­ç«‹ã¨åˆ†é¡ã•ã‚Œã‚‹å‚¾å‘:\n\n")
        f.write("**ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ»ãƒ•ãƒ¬ãƒ¼ã‚º**:\n")
        f.write("- äº‹å®Ÿå ±å‘Š: update, information, fact, data, report\n")
        f.write("- é€²è¡ŒçŠ¶æ³: currently, working on, in progress, planned\n")
        f.write("- å®¢è¦³çš„è¨˜è¿°: scheduled, status, details\n\n")
        
        f.write("**æ–‡è„ˆçš„è¦ç´ **:\n")
        f.write("- æ„Ÿæƒ…çš„ãªåˆ¤æ–­ã‚’å«ã¾ãªã„äº‹å®Ÿã®å ±å‘Š\n")
        f.write("- æŠ€è¡“ä»•æ§˜ã‚„æ•°å€¤ãƒ‡ãƒ¼ã‚¿ã®å…±æœ‰\n")
        f.write("- ãƒ—ãƒ­ã‚»ã‚¹ã‚„æ‰‹é †ã®èª¬æ˜\n")
        f.write("- ãƒã‚¸ãƒ†ã‚£ãƒ–ã¨ãƒã‚¬ãƒ†ã‚£ãƒ–ãŒæ··åœ¨\n\n")
        
        # 3. Distribution Analysis
        f.write("## 3. å®Ÿéš›ã®åˆ†é¡çµæœã®åˆ†å¸ƒ\n\n")
        
        sentiment_counts = df['sentiment'].value_counts()
        total = len(df)
        
        f.write("### æ„Ÿæƒ…åˆ†é¡ã®å†…è¨³\n")
        f.write("| æ„Ÿæƒ… | ä»¶æ•° | å‰²åˆ | å¹³å‡ä¿¡é ¼åº¦ |\n")
        f.write("|------|------|------|------------|\n")
        
        for sentiment in ['BULLISH', 'BEARISH', 'NEUTRAL']:
            count = sentiment_counts.get(sentiment, 0)
            pct = count / total * 100
            avg_conf = df[df['sentiment'] == sentiment]['confidence'].mean()
            f.write(f"| {sentiment} | {count} | {pct:.1f}% | {avg_conf:.3f} |\n")
        
        # 4. Specific Examples
        f.write("\n## 4. å…·ä½“çš„ãªåˆ†é¡ä¾‹\n\n")
        
        for sentiment, examples in samples.items():
            f.write(f"### {sentiment} ã®ä¾‹ï¼ˆä¿¡é ¼åº¦ã®é«˜ã„é †ï¼‰\n\n")
            for i, example in enumerate(examples[:3], 1):
                f.write(f"**ä¾‹{i}** (ä¿¡é ¼åº¦: {example['confidence']:.3f})\n")
                f.write(f"```\n{example['tweet_text']}\n```\n\n")
        
        # 5. Edge Cases
        f.write("## 5. ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ã¨æ›–æ˜§ãªä¾‹\n\n")
        
        # Low confidence examples
        low_conf = df[df['confidence'] < 0.6].nlargest(5, 'confidence')
        
        f.write("### ä½ä¿¡é ¼åº¦ã®ä¾‹ï¼ˆåˆ†é¡ãŒå›°é›£ã ã£ãŸã‚±ãƒ¼ã‚¹ï¼‰\n\n")
        for _, row in low_conf.iterrows():
            f.write(f"**{row['sentiment']}** (ä¿¡é ¼åº¦: {row['confidence']:.3f})\n")
            f.write(f"```\n{row['tweet_text'][:200]}...\n```\n\n")
        
        # 6. Fallback Classification
        f.write("## 6. ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯åˆ†é¡\n\n")
        f.write("LLMãŒåˆ©ç”¨ã§ããªã„å ´åˆã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹åˆ†é¡:\n\n")
        f.write("```python\n")
        f.write("bullish_keywords = ['great', 'amazing', 'bullish', 'moon', 'rocket', \n")
        f.write("                    'breakthrough', 'record', 'best']\n")
        f.write("bearish_keywords = ['problem', 'issue', 'difficult', 'challenge', \n")
        f.write("                    'delay', 'recall']\n")
        f.write("\n")
        f.write("text_lower = tweet_text.lower()\n")
        f.write("bullish_score = sum(1 for word in bullish_keywords if word in text_lower)\n")
        f.write("bearish_score = sum(1 for word in bearish_keywords if word in text_lower)\n")
        f.write("\n")
        f.write("if bullish_score > bearish_score:\n")
        f.write("    return 'BULLISH', 0.5, 'Keyword-based analysis'\n")
        f.write("elif bearish_score > bullish_score:\n")
        f.write("    return 'BEARISH', 0.5, 'Keyword-based analysis'\n")
        f.write("else:\n")
        f.write("    return 'NEUTRAL', 0.5, 'Keyword-based analysis'\n")
        f.write("```\n\n")
        
        # 7. Validation
        f.write("## 7. åˆ†é¡ã®æ¤œè¨¼\n\n")
        
        # Cross-sentiment characteristics
        f.write("### æ„Ÿæƒ…åˆ¥ã®ç‰¹å¾´åˆ†æ\n\n")
        
        characteristics = ['is_product_announcement', 'contains_metrics', 'forward_looking']
        
        f.write("| ç‰¹å¾´ | BULLISH | BEARISH | NEUTRAL |\n")
        f.write("|------|---------|---------|----------|\n")
        
        for char in characteristics:
            row = f"| {char} |"
            for sentiment in ['BULLISH', 'BEARISH', 'NEUTRAL']:
                sentiment_df = df[df['sentiment'] == sentiment]
                if len(sentiment_df) > 0:
                    pct = (sentiment_df[char] == True).sum() / len(sentiment_df) * 100
                    row += f" {pct:.1f}% |"
                else:
                    row += " N/A |"
            f.write(row + "\n")
        
        # 8. Missing Categories
        f.write("\n## 8. åˆ†é¡ã•ã‚Œãªã„ã‚±ãƒ¼ã‚¹\n\n")
        f.write("ä»¥ä¸‹ã®ã‚±ãƒ¼ã‚¹ã§ã¯åˆ†é¡ãŒå›°é›£ã¾ãŸã¯ä¸é©åˆ‡:\n\n")
        f.write("1. **Teslaä»¥å¤–ã®è©±é¡Œ**: SpaceXã‚„Neuralinkç­‰ã®ä»–ç¤¾ã®è©±é¡Œ\n")
        f.write("2. **ãƒªãƒ—ãƒ©ã‚¤ã‚„ãƒªãƒ„ã‚¤ãƒ¼ãƒˆ**: æ–‡è„ˆãŒä¸å®Œå…¨ãªçŸ­ã„å¿œç­”\n")
        f.write("3. **ã‚¸ãƒ§ãƒ¼ã‚¯ã‚„ãƒŸãƒ¼ãƒ **: çœŸå‰£ãªæ„å›³ãŒä¸æ˜ç¢º\n")
        f.write("4. **æ¥µç«¯ã«çŸ­ã„ãƒ„ã‚¤ãƒ¼ãƒˆ**: çµµæ–‡å­—ã®ã¿ã€å˜èªã®ã¿\n\n")
        
        # 9. Reproducibility
        f.write("## 9. å†ç¾æ€§ã®ç¢ºä¿\n\n")
        f.write("### å¿…è¦ãªç’°å¢ƒ\n")
        f.write("```bash\n")
        f.write("pip install openai==1.98.0 anthropic==0.60.0 pandas matplotlib seaborn\n")
        f.write("```\n\n")
        
        f.write("### ç’°å¢ƒå¤‰æ•°\n")
        f.write("```bash\n")
        f.write("export OPENAI_API_KEY='your-openai-key'\n")
        f.write("export ANTHROPIC_API_KEY='your-anthropic-key'\n")
        f.write("```\n\n")
        
        f.write("### å®Ÿè¡Œã‚³ãƒãƒ³ãƒ‰\n")
        f.write("```bash\n")
        f.write("python tesla_sentiment_analysis.py\n")
        f.write("python tesla_multi_condition_analysis.py\n")
        f.write("python sentiment_classification_methodology.py\n")
        f.write("```\n\n")
        
        f.write("## 10. åˆ¶é™äº‹é …ã¨æ”¹å–„ç‚¹\n\n")
        f.write("1. **æ™‚é–“çš„æ–‡è„ˆã®æ¬ å¦‚**: éå»ã®ãƒ„ã‚¤ãƒ¼ãƒˆã‚„ãƒ‹ãƒ¥ãƒ¼ã‚¹ã¨ã®é–¢é€£ãŒè€ƒæ…®ã•ã‚Œã¦ã„ãªã„\n")
        f.write("2. **çš®è‚‰ã‚„æš—ç¤ºã®ç†è§£**: LLMã¯çš®è‚‰ã‚„å¾®å¦™ãªæš—ç¤ºã‚’èª¤è§£ã™ã‚‹å¯èƒ½æ€§\n")
        f.write("3. **å¸‚å ´ã®æœŸå¾…ã¨ã®ä¹–é›¢**: å¼·æ°—ã§ã‚‚å¸‚å ´ã®æœŸå¾…ã‚’ä¸‹å›ã‚Œã°æ ªä¾¡ã¯ä¸‹è½\n")
        f.write("4. **ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚º**: BEARISH tweets ãŒå°‘ãªã„ï¼ˆ6ä»¶ã®ã¿ï¼‰\n\n")
        
        f.write("---\n\n")
        f.write("ã“ã®ãƒ¬ãƒãƒ¼ãƒˆã¯å®Œå…¨ãªå†ç¾æ€§ã‚’ç¢ºä¿ã™ã‚‹ãŸã‚ã€ã™ã¹ã¦ã®åˆ¤æ–­åŸºæº–ã€")
        f.write("ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã€ã‚³ãƒ¼ãƒ‰ã€ãŠã‚ˆã³å…·ä½“ä¾‹ã‚’å«ã‚“ã§ã„ã¾ã™ã€‚\n")


def main():
    """Run methodology analysis and generate report"""
    
    output_dir = '/Users/kumacmini/Library/CloudStorage/Dropbox/Workspace/Hypothesis-Verification'
    
    print("Analyzing sentiment classification methodology...")
    
    # Load data
    df, tweets = load_analysis_data()
    if df is None:
        print("Failed to load data")
        return
    
    # Analyze sentiment distribution
    sentiment_counts, confidence_stats, samples = analyze_sentiment_distribution(df)
    
    # Extract patterns
    patterns = extract_classification_patterns(df)
    
    # Create visualizations
    print("Creating methodology visualizations...")
    create_methodology_visualizations(df, output_dir)
    
    # Generate report
    print("Generating detailed methodology report...")
    generate_methodology_report(df, patterns, samples, output_dir)
    
    # Save detailed classification data
    classification_details = []
    for _, row in df.iterrows():
        detail = {
            'tweet_id': row['tweet_id'],
            'tweet_text': row['tweet_text'],
            'sentiment': row['sentiment'],
            'confidence': row['confidence'],
            'is_product_announcement': row['is_product_announcement'],
            'contains_metrics': row['contains_metrics'],
            'forward_looking': row['forward_looking'],
            'topic_category': row['topic_category'],
            'urgency_level': row['urgency_level']
        }
        classification_details.append(detail)
    
    # Save as JSON for complete transparency
    with open(f'{output_dir}/sentiment_classification_details.json', 'w', encoding='utf-8') as f:
        json.dump(classification_details, f, ensure_ascii=False, indent=2)
    
    print("Methodology documentation complete!")


if __name__ == "__main__":
    main()